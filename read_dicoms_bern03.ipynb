{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import cm\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.misc\n",
    "from scipy import ndimage\n",
    "import h5py\n",
    "\n",
    "import tensorflow as tf\n",
    "# print(tf.__version__)\n",
    "\n",
    "# plot the image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load information file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/hezo/Dropbox/PhD/Stroke/Stroke_perfusion/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_table(path + \"data/data_to_read_in.csv\", sep = \",\", encoding = \"latin-1\", low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dat[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = dat.sort_values([\"p_id\", \"modality\", \"instance_no\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dat[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how duplicated works\n",
    "# x = pd.DataFrame({\"x\": [1,1,2,2,3,4,3,4], \"y\": 1})\n",
    "# print(x.duplicated(\"x\"))\n",
    "# print(x.index[x.duplicated(\"x\")])\n",
    "\n",
    "# p = np.unique(dat.p_id.values)[0]\n",
    "# pat = dat.loc[dat.p_id == p,:]\n",
    "# pat_m = pat.loc[pat.modality == np.unique(pat.modality)[0]]\n",
    "# pat_m.index[pat_m.duplicated(\"instance_no\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for duplicated instance numbers\n",
    "idx = []\n",
    "for p in np.unique(dat.p_id.values):\n",
    "    pat = dat.loc[dat.p_id == p,:]\n",
    "    for m in np.unique(pat.modality):\n",
    "        pat_m = pat.loc[pat.modality == m]\n",
    "        idx.append(pat_m.index[pat_m.duplicated(\"instance_no\")])\n",
    "\n",
    "# combine the arrays in the list to one array with the indices:\n",
    "idx = np.hstack(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete duplicates\n",
    "dat0 = dat\n",
    "dat = dat.drop(index = idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run again to check if all duplicated instance numbers are gone\n",
    "idx = []\n",
    "for p in np.unique(dat.p_id.values):\n",
    "    pat = dat.loc[dat.p_id == p,:]\n",
    "    for m in np.unique(pat.modality):\n",
    "        pat_m = pat.loc[pat.modality == m]\n",
    "        idx.append(pat_m.index[pat_m.duplicated(\"instance_no\")])\n",
    "\n",
    "# combine the arrays in the list to one array with the indices:\n",
    "idx = np.hstack(idx)\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the index\n",
    "print(dat.index[:10])\n",
    "dat = dat.reset_index(drop = True)\n",
    "dat.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check image dimensions\n",
    "\n",
    "# quadratic images?\n",
    "all(dat.loc[:,\"columns\"] == dat.loc[:,\"rows\"])\n",
    "\n",
    "# same number of pixels per modality?\n",
    "for i in np.unique(dat.modality):\n",
    "    print(i, np.unique(dat.loc[dat.modality == i, \"columns\"], return_counts = True))\n",
    "    \n",
    "# number of images per modality per patient\n",
    "for i in np.unique(dat.modality):\n",
    "    print(i, np.unique(dat.loc[dat.modality == i, \"p_id\"], return_counts = True)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check DICOM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider a dicom as example image\n",
    "slice_ex = pydicom.read_file(dat.path[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "slice_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a slice from each modality from one patient\n",
    "dat_pat = dat.loc[dat.p_id == 442968, :] #516341\n",
    "\n",
    "i = 10\n",
    "slice_adc = pydicom.read_file(dat_pat.loc[dat_pat.modality == \"ADC\", \"path\"].values[i])\n",
    "slice_dwi = pydicom.read_file(dat_pat.loc[dat_pat.modality == \"DWI\", \"path\"].values[i])\n",
    "slice_cbf = pydicom.read_file(dat_pat.loc[dat_pat.modality == \"CBF\", \"path\"].values[i])\n",
    "slice_cbv = pydicom.read_file(dat_pat.loc[dat_pat.modality == \"CBV\", \"path\"].values[i])\n",
    "slice_tmax = pydicom.read_file(dat_pat.loc[dat_pat.modality == \"TMAX\", \"path\"].values[i])\n",
    "slice_mtt = pydicom.read_file(dat_pat.loc[dat_pat.modality == \"MTT\", \"path\"].values[i])\n",
    "slice_ttp = pydicom.read_file(dat_pat.loc[dat_pat.modality == \"TTP\", \"path\"].values[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "example_slices = [0, slice_adc.pixel_array, \n",
    "                  slice_dwi.pixel_array, \n",
    "                  slice_cbf.pixel_array, \n",
    "                  slice_cbv.pixel_array, \n",
    "                  slice_tmax.pixel_array, \n",
    "                  slice_mtt.pixel_array, \n",
    "                  slice_ttp.pixel_array]\n",
    "fig=plt.figure(figsize=(15, 15))\n",
    "columns = 7\n",
    "rows = 1\n",
    "for i in range(1, columns*rows +1):\n",
    "    img = example_slices[i]\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# slice thickness & pixel spacing: (seems to change with patients...)\n",
    "# ADC slices are 5mm and each voxel represents 1.8mm\n",
    "print(slice_adc.SliceThickness, slice_adc.PixelSpacing)\n",
    "print(slice_dwi.SliceThickness, slice_dwi.PixelSpacing)\n",
    "print(slice_cbf.SliceThickness, slice_cbf.PixelSpacing)\n",
    "print(slice_cbv.SliceThickness, slice_cbv.PixelSpacing)\n",
    "print(slice_mtt.SliceThickness, slice_mtt.PixelSpacing)\n",
    "print(slice_tmax.SliceThickness, slice_tmax.PixelSpacing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read DICOM data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read slices of one patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checked how drop_duplicates() works\n",
    "# dat0 = pd.DataFrame({\"name\": [1,1,2,2,3,3,4,4,5,5,6,6,7,7], \"var\": [1,2,3,4,5,6,7,8,9,10,11,12,13,14]})\n",
    "# dat0.drop_duplicates(\"name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_slice = slice_cbf\n",
    "ref_slice.pixel_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modality = \"TMAX\"\n",
    "pat = dat.loc[(dat.p_id == np.unique(dat.p_id)[100]) & (dat.modality == modality),]\n",
    "\n",
    "# make sure that the images are in the correct order and that there are no duplicated series\n",
    "pat = pat.sort_values(\"instance_no\")\n",
    "pat = pat.drop_duplicates(\"instance_no\")\n",
    "\n",
    "# take a reference slice and save information\n",
    "ref_slice = pydicom.read_file(pat.path.values[0])\n",
    "pat[\"pixel_spacing_x\"] = float(ref_slice.PixelSpacing[0])\n",
    "pat[\"pixel_spacing_y\"] = float(ref_slice.PixelSpacing[1])\n",
    "pat[\"pixel_spacing_z\"] = float(ref_slice.SliceThickness)\n",
    "\n",
    "# array to store the images\n",
    "X = np.ndarray((ref_slice.Rows, ref_slice.Columns, len(pat), ref_slice.pixel_array.shape[2]), dtype = \"int\")\n",
    "\n",
    "# load slices\n",
    "for i, p in enumerate(pat.path.values):\n",
    "    slice_tmp = pydicom.read_file(p)\n",
    "    X[:,:,i] = slice_tmp.pixel_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_slices(X, pat, plane = [\"axial\", \"coronal\", \"sagittal\"], modality = \"perfusion\"):\n",
    "    # total figure size (including all subplots)\n",
    "    nslices = X.shape[2]\n",
    "    ncols = 6\n",
    "    nrows = int(nslices / ncols)\n",
    "    base_size = 2\n",
    "    aspect_ratio = 0.5\n",
    "    # ax_aspect = pat.pixel_spacing_y.values[0]/pat.pixel_spacing_x.values[0]\n",
    "    # cor_aspect = pat.pixel_spacing_z.values[0]/pat.pixel_spacing_x.values[0]\n",
    "    # sag_aspect = pat.pixel_spacing_y.values[0]/pat.pixel_spacing_z.values[0]\n",
    "\n",
    "    figsize = (ncols*3, nrows*3)\n",
    "    fig = plt.figure(figsize = figsize)\n",
    "    \n",
    "    if plane == \"axial\":\n",
    "        fig_all = []\n",
    "        for i in range(1, ncols*nrows):\n",
    "            if modality != \"perfusion\":\n",
    "                img = X[:,:,i,0]\n",
    "                fig_all.append(fig.add_subplot(nrows, ncols, i))\n",
    "                plt.imshow(img)\n",
    "            else:\n",
    "                img = X[:,:,i,:]\n",
    "                fig_all.append(fig.add_subplot(nrows, ncols, i))\n",
    "                plt.imshow(img)\n",
    "        plt.show()\n",
    "    if plane == \"coronal\":\n",
    "        # which images do we want to consider\n",
    "        idx = int(X.shape[1]/(ncols*nrows))\n",
    "        idx = list(range(0, X.shape[1], idx))\n",
    "        fig_all = []\n",
    "        for i in range(1, ncols*nrows):\n",
    "            if modality != \"perfusion\":\n",
    "                img = X[idx[i],:,:,0]\n",
    "                fig_all.append(fig.add_subplot(nrows, ncols, i))\n",
    "                plt.imshow(img, aspect = \"auto\")\n",
    "            else:\n",
    "                img = X[idx[i],:,:,:]\n",
    "                fig_all.append(fig.add_subplot(nrows, ncols, i))\n",
    "                plt.imshow(img, aspect = \"auto\")\n",
    "        plt.show()\n",
    "    if plane == \"sagittal\":\n",
    "        # which images do we want to consider\n",
    "        idx = int(X.shape[0]/(ncols*nrows))\n",
    "        idx = list(range(0, X.shape[0], idx))\n",
    "        fig_all = []\n",
    "        for i in range(1, ncols*nrows):\n",
    "            if modality != \"perfusion\":\n",
    "                img = X[:,idx[i],:,0]\n",
    "                fig_all.append(fig.add_subplot(nrows, ncols, i))\n",
    "                plt.imshow(img, aspect = \"auto\")\n",
    "            else:\n",
    "                img = X[:,idx[i],:,:]\n",
    "                fig_all.append(fig.add_subplot(nrows, ncols, i))\n",
    "                plt.imshow(img, aspect = \"auto\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_slices(X, pat, \"axial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_slices(X, pat, \"coronal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_slices(X, pat, \"sagittal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# remove the bar and the name\n",
    "plt.imshow(X[:40,:50,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modality = \"TMAX\"\n",
    "pat = dat.loc[(dat.p_id == np.unique(dat.p_id)[100]) & (dat.modality == modality),]\n",
    "\n",
    "# make sure that the images are in the correct order and that there are no duplicated series\n",
    "pat = pat.sort_values(\"instance_no\")\n",
    "pat = pat.drop_duplicates(\"instance_no\")\n",
    "\n",
    "# take a reference slice and save information\n",
    "ref_slice = pydicom.read_file(pat.path.values[0])\n",
    "pat[\"pixel_spacing_x\"] = float(ref_slice.PixelSpacing[0])\n",
    "pat[\"pixel_spacing_y\"] = float(ref_slice.PixelSpacing[1])\n",
    "pat[\"pixel_spacing_z\"] = float(ref_slice.SliceThickness)\n",
    "\n",
    "# array to store the images\n",
    "X = np.ndarray((ref_slice.Rows, ref_slice.Columns, len(pat), ref_slice.pixel_array.shape[2]), dtype = \"int\")\n",
    "\n",
    "# load slices\n",
    "for i, p in enumerate(pat.path.values):\n",
    "    slice_tmp = pydicom.read_file(p)\n",
    "    X[:,:,i] = slice_tmp.pixel_array\n",
    "    \n",
    "    # remove modality name and color bar for OLEA images\n",
    "    if(modality in [\"CBF\", \"CBV\", \"TMAX\", \"MTT\", \"TTP\"]):\n",
    "        X[:40,:50,i] = 0\n",
    "        X[:,200:,i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_slice.pixel_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_slices(X, pat, \"axial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read one patient\n",
    "def load_slices(dat, modality, p_id):\n",
    "    pat = dat.loc[(dat.p_id == p_id) & (dat.modality == modality),]\n",
    "    \n",
    "    # make sure that the images are in the correct order and that there are no duplicated series\n",
    "    pat = pat.sort_values(\"instance_no\")\n",
    "    pat = pat.drop_duplicates(\"instance_no\")\n",
    "    \n",
    "    # take a reference slice and save information\n",
    "    ref_slice = pydicom.read_file(pat.path.values[0])\n",
    "    pat[\"pixel_spacing_x\"] = float(ref_slice.PixelSpacing[0])\n",
    "    pat[\"pixel_spacing_y\"] = float(ref_slice.PixelSpacing[1])\n",
    "    pat[\"pixel_spacing_z\"] = float(ref_slice.SliceThickness)\n",
    "    \n",
    "    # array to store the images\n",
    "    if modality in [\"DWI\", \"ADC\"]:\n",
    "        X = np.ndarray((ref_slice.Rows, ref_slice.Columns, len(pat), 1), dtype = \"int\")\n",
    "    else:\n",
    "        X = np.ndarray((ref_slice.Rows, ref_slice.Columns, len(pat), ref_slice.pixel_array.shape[2]), dtype = \"int\")\n",
    "    \n",
    "    # load slices\n",
    "    for i, p in enumerate(pat.path.values):\n",
    "        slice_tmp = pydicom.read_file(p)\n",
    "        if(modality in [\"DWI\", \"ADC\"]):\n",
    "            X[:,:,i,0] = slice_tmp.pixel_array\n",
    "        \n",
    "        # remove modality name and color bar for OLEA images\n",
    "        if(modality in [\"CBF\", \"CBV\", \"TMAX\", \"MTT\", \"TTP\"]):\n",
    "            X[:,:,i,:] = slice_tmp.pixel_array\n",
    "            X[:40,:50,i,:] = 0\n",
    "            X[:,200:,i,:] = 0\n",
    "        \n",
    "            \n",
    "    return X, pat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, pat = load_slices(dat, \"ADC\", np.unique(dat.p_id)[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_slices(X, pat, \"coronal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pat.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(X), np.max(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data\n",
    "dim = (128, 128, 64, 3)\n",
    "scaling_factor = [dim[0]/X.shape[0], dim[1]/X.shape[1], dim[2]/X.shape[2], dim[3]/X.shape[3]]\n",
    "X_scaled = ndimage.zoom(X, scaling_factor, order = 1) # order = 1: linear interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(X_scaled.shape, np.min(X_scaled), np.max(X_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_slices(X_scaled, pat, \"axial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dat_cbf = pd.DataFrame(index=range(1), columns=pat.columns)\n",
    "# dat_cbf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read all patients from one modality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all patients and all modalities\n",
    "n = len(np.unique(dat.p_id)[:2])\n",
    "dat_mod = pd.DataFrame(index = range(1), columns = pat.columns)\n",
    "mod = \"CBF\"\n",
    "dim = (128, 128, 64, 3)\n",
    "X_mod = np.zeros((n, 128, 128, 64, 3), dtype = \"uint8\")\n",
    "\n",
    "for i, p_id in enumerate(np.unique(dat.p_id)[:2]):\n",
    "    X_tmp, pat_tmp = load_slices(dat, mod, p_id)\n",
    "    scaling_factor = [dim[0]/X_tmp.shape[0], dim[1]/X_tmp.shape[1], dim[2]/X_tmp.shape[2], dim[3]/X_tmp.shape[3]]\n",
    "    X_scaled = ndimage.zoom(X_tmp, scaling_factor, order = 1)\n",
    "    X_mod[i,:,:,:,:] = X_scaled\n",
    "    dat_mod = dat_mod.append(pat_tmp.iloc[0]) # we only need one row because we consider each patient now\n",
    "\n",
    "dat_mod = dat_mod.reset_index(drop = True)\n",
    "dat_mod = dat_mod.drop(index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_slices(X_mod[0], dat_mod, \"axial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_patient(dat, modality):\n",
    "    # read all patients and all modalities\n",
    "    n = len(np.unique(dat.p_id))\n",
    "    dat_mod = pd.DataFrame(index = range(1), columns = pat.columns)\n",
    "    mod = modality\n",
    "    \n",
    "    if mod in [\"DWI\", \"ADC\"]:\n",
    "        dim = (128, 128, 64, 1)\n",
    "        X_mod = np.zeros((n, 128, 128, 64, 1), dtype = \"uint16\")\n",
    "    else:\n",
    "        dim = (128, 128, 64, 3)\n",
    "        X_mod = np.zeros((n, 128, 128, 64, 3), dtype = \"uint16\")\n",
    "    \n",
    "    \n",
    "    for i, p_id in enumerate(np.unique(dat.p_id)):\n",
    "        X_tmp, pat_tmp = load_slices(dat, mod, p_id)\n",
    "        scaling_factor = [dim[0]/X_tmp.shape[0], dim[1]/X_tmp.shape[1], dim[2]/X_tmp.shape[2], dim[3]/X_tmp.shape[3]]\n",
    "        X_scaled = ndimage.zoom(X_tmp, scaling_factor, order = 1)\n",
    "        X_mod[i,:,:,:,:] = X_scaled\n",
    "        dat_mod = dat_mod.append(pat_tmp.iloc[0]) # we only need one row because we consider each patient now\n",
    "    \n",
    "    dat_mod = dat_mod.reset_index(drop = True)\n",
    "    dat_mod = dat_mod.drop(index = 0)\n",
    "    \n",
    "    return X_mod, dat_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read patients: perfusion maps\n",
    "X_cbf, dat_cbf = read_patient(dat, \"CBF\")\n",
    "X_cbv, dat_cbv = read_patient(dat, \"CBV\")\n",
    "X_mtt, dat_mtt = read_patient(dat, \"MTT\")\n",
    "X_ttp, dat_ttp = read_patient(dat, \"TTP\")\n",
    "X_tmax, dat_tmax = read_patient(dat, \"TMAX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read patients: diffusion maps\n",
    "X_dwi, dat_dwi = read_patient(dat, \"DWI\")\n",
    "X_adc, dat_adc = read_patient(dat, \"ADC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_slices(X_ttp[10], dat_ttp.iloc[10,:], \"axial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_slices(X_dwi[10], dat_dwi.iloc[10,:], \"axial\", modality = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to HDF5\n",
    "with h5py.File(\"C:/Users/hezo/Dropbox/PhD/Stroke/Stroke_perfusion/data/data_bern_25_11_2020.h5\", \"w\") as h5:\n",
    "    # Image matrices\n",
    "    h5.create_dataset(\"X_dwi\", data=X_dwi)\n",
    "    h5.create_dataset(\"X_adc\", data=X_adc)\n",
    "    h5.create_dataset(\"X_cbf\", data=X_cbf)\n",
    "    h5.create_dataset(\"X_cbv\", data=X_cbv)\n",
    "    h5.create_dataset(\"X_mtt\", data=X_mtt)\n",
    "    h5.create_dataset(\"X_ttp\", data=X_ttp)\n",
    "    h5.create_dataset(\"X_tmax\", data=X_tmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_dwi.to_csv(\"C:/Users/hezo/Dropbox/PhD/Stroke/Stroke_perfusion/data/data_bern_25_11_2020_dwi.csv\", index = False)\n",
    "dat_adc.to_csv(\"C:/Users/hezo/Dropbox/PhD/Stroke/Stroke_perfusion/data/data_bern_25_11_2020_adc.csv\", index = False)\n",
    "dat_cbf.to_csv(\"C:/Users/hezo/Dropbox/PhD/Stroke/Stroke_perfusion/data/data_bern_25_11_2020_cbf.csv\", index = False)\n",
    "dat_cbv.to_csv(\"C:/Users/hezo/Dropbox/PhD/Stroke/Stroke_perfusion/data/data_bern_25_11_2020_cbv.csv\", index = False)\n",
    "dat_mtt.to_csv(\"C:/Users/hezo/Dropbox/PhD/Stroke/Stroke_perfusion/data/data_bern_25_11_2020_mtt.csv\", index = False)\n",
    "dat_ttp.to_csv(\"C:/Users/hezo/Dropbox/PhD/Stroke/Stroke_perfusion/data/data_bern_25_11_2020_ttp.csv\", index = False)\n",
    "dat_tmax.to_csv(\"C:/Users/hezo/Dropbox/PhD/Stroke/Stroke_perfusion/data/data_bern_25_11_2020_tmax.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read the images into an array\n",
    "# # all perfusion images are of size 256x256x3\n",
    "# # ADC/DWI images vary\n",
    "# # Resize all images to 256x256x3\n",
    "# \n",
    "# def read_images(dat, image_size):\n",
    "#     # define the array to store the images\n",
    "#     X = np.zeros((len(dat.path), image_size, image_size, 3), dtype=np.int16) \n",
    "#     for i, (_, row) in enumerate(dat.iterrows()): # iterate over the rows and i = row value not index\n",
    "#         print(i)\n",
    "#         img_in = pydicom.read_file(row.path)\n",
    "#         # make sure that all images have equal size\n",
    "#         img = scipy.misc.imresize(img_in.pixel_array, (image_size, image_size), interp = 'cubic')\n",
    "#         \n",
    "#         # For the DWI's and ADC's we repeat the image in the three colour channels\n",
    "#         if row.modality == \"ADC\" or row.modality == \"DWI\":\n",
    "#             X[i, :, :, 0] = img\n",
    "#             X[i, :, :, 1] = img\n",
    "#             X[i, :, :, 2] = img\n",
    "#         else:\n",
    "#             X[i, :, :, :] = img\n",
    "#     return(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X = read_images(dat, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to get the spacing in the three dimensions\n",
    "# def get_spacing(dat):\n",
    "#     x = []\n",
    "#     y = []\n",
    "#     z = []\n",
    "#     # define the array to store the images\n",
    "#     for i, (_, row) in enumerate(dat.iterrows()): # iterate over the rows and i = row value not index\n",
    "#         img_in = pydicom.read_file(row.path)\n",
    "#         x.append(img_in.PixelSpacing[0])\n",
    "#         y.append(img_in.PixelSpacing[1])\n",
    "#         z.append(img_in.SliceThickness)\n",
    "#     return(x, y, z)\n",
    "# \n",
    "# x, y, z = get_spacing(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dat[\"spacing_x\"] = x\n",
    "# dat[\"spacing_y\"] = y\n",
    "# dat[\"spacing_z\"] = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dat.to_csv(path + \"data/data_march20_information.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import h5py\n",
    "# \n",
    "# # Encode strings to save\n",
    "# def encode_data(string):\n",
    "#     encoded_string = [n.encode(\"UTF-8\", \"ignore\") for n in string]\n",
    "#     return(encoded_string)\n",
    "# \n",
    "# # write to HDF5\n",
    "# with h5py.File(\"C:/Users/hezo/Dropbox/PhD/Stroke/Stroke_perfusion/data/data_march_20.h5\", \"w\") as h5:\n",
    "#     # Image matrices\n",
    "#     h5.create_dataset(\"X\", data=X)\n",
    "#     # Path: Then we can merge the data and the labels later again\n",
    "#     h5.create_dataset(\"path\", data=encode_data(dat.path.get_values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consider the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to HDF5\n",
    "with h5py.File(\"C:/Users/hezo/Dropbox/PhD/Stroke/Stroke_perfusion/data/data_bern_25_11_2020.h5\", \"r\") as h5:\n",
    "    # Image matrices\n",
    "    X_cbf = h5[\"X_cbf\"][:]\n",
    "    X_tmax = h5[\"X_tmax\"][:]\n",
    "    X_dwi = h5[\"X_dwi\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_cbf = pd.read_csv(\"C:/Users/hezo/Dropbox/PhD/Stroke/Stroke_perfusion/data/data_bern_25_11_2020_cbf.csv\")\n",
    "dat_tmax = pd.read_csv(\"C:/Users/hezo/Dropbox/PhD/Stroke/Stroke_perfusion/data/data_bern_25_11_2020_tmax.csv\")\n",
    "dat_dwi = pd.read_csv(\"C:/Users/hezo/Dropbox/PhD/Stroke/Stroke_perfusion/data/data_bern_25_11_2020_dwi.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_slices(X_dwi[20], dat_dwi.iloc[20,:], \"axial\", modality = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_slices(X_cbf[20], dat_cbf.iloc[20,:], \"axial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_slices(X_tmax[20], dat_tmax.iloc[20,:], \"axial\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
